The Gesture and Voice-Controlled Media Player is an AI-driven system that enables fully touch-free interaction using hand gestures and voice commands.

Key technologies include:

Computer Vision (OpenCV + Mediapipe) for capturing hand landmarks

CNN-based Gesture Classification Model for recognizing gestures

Speech Recognition for audio-based commands

Python GUI for media playback

This project demonstrates applied AI engineering, real-time processing, and multimodal user interaction.

ğŸ–¼ï¸ output of the project
<img width="1653" height="1072" alt="Screenshot 2025-06-10 221722" src="https://github.com/user-attachments/assets/1d08e554-5c64-4fca-8636-80f905606cfa" />

ğŸš€ Features
âœ‹ Gesture Controls (CNN-powered)

Play / Pause

Next / Previous Track

Volume Up / Down

Seek Forward / Backward

Real-time gesture detection using a trained CNN model

ğŸ¤ Voice Command Controls

â€œPlayâ€, â€œPauseâ€, â€œNextâ€, â€œMuteâ€, etc.

Real-time microphone input processing

ğŸ§  AI Features

CNN-based gesture classification

Hand landmark tracking with Mediapipe

NLP-style audio command mapping

ğŸ› ï¸ Tech Stack
Component	Technology
Language	Python
Computer Vision	OpenCV, Mediapipe
Gesture Recognition	Custom CNN Model
Audio Processing	SpeechRecognition, PyAudio
UI Framework	PyQt / Tkinter
Dataset	Custom gesture dataset


ğŸ”§ Installation
git clone https://github.com/<your-username>/<repo>.git
cd <repo>
pip install -r requirements.txt


ğŸ¯ Highlights

CNN-powered gesture classification

Real-time CV + Audio processing

Smooth multimodal AI experience

Ideal for AI/ML + CV portfolio

Demonstrates practical implementation of ML models

ğŸ¤ Contributing

Contributions and feature ideas are welcome!

ğŸ“¬ Contact : 

Aniket Agarkhed
Email: aniketagarkhed@gmail.com
GitHub:[aniket1821-vk](https://github.com/aniket1821-vk)
